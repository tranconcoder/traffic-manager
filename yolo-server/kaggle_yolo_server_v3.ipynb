{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üö¶ Traffic Manager AI Platform (V2)\n",
                "**Hybrid Engine**: YOLO11m (Vehicles) + YOLOv5 (License Plates)\n",
                "\n",
                "### Instructions:\n",
                "1. **Settings**: Enable **GPU** and **Internet** in Kaggle settings sidebar.\n",
                "2. **Upload**: Upload your custom models (`mhiot-vehicle...` etc.) if you have them. If not, the script downloads YOLO11m automatically.\n",
                "3. **Config**: Update `SOCKETIO_SERVER_URL` in the code below to your Ngrok URL.\n",
                "4. **Run**: Run all cells."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# üì¶ Install Dependencies\n",
                "!pip install ultralytics python-socketio[client] websocket-client opencv-python-headless pillow --quiet\n",
                "print(\"‚úÖ Dependencies Installed\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# üì• Pre-download YOLO11m Model (To avoid hanging during init)\n",
                "print(\"‚è≥ Downloading YOLO11m model... (Please wait)\")\n",
                "!wget -nc https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11m.pt\n",
                "print(\"‚úÖ Model ready\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import cv2\n",
                "import numpy as np\n",
                "import socketio\n",
                "import base64\n",
                "import time\n",
                "import threading\n",
                "import queue\n",
                "import io\n",
                "import torch\n",
                "import math\n",
                "import os\n",
                "import sys\n",
                "from PIL import Image\n",
                "from ultralytics import YOLO\n",
                "\n",
                "# ---------------- CONFIGURATION ----------------\n",
                "# ‚ö†Ô∏è UPDATE THIS URL TO YOUR NGROK URL:\n",
                "SOCKETIO_SERVER_URL = 'wss://unadjourned-darlene-subcarinated.ngrok-free.dev' \n",
                "CONFIDENCE_THRESHOLD = 0.5\n",
                "\n",
                "# Model Paths\n",
                "VEHICLE_MODEL_PATH = 'yolo11m.pt'               # YOLO11m (User requested)\n",
                "# VEHICLE_MODEL_PATH = 'mhiot-vehicle-best-new.pt' # Custom model option\n",
                "TRAFFIC_LIGHT_MODEL_PATH = 'mhiot-dentinhieu-best-new.pt'\n",
                "LP_DETECTOR_PATH = 'LP_detector.pt'\n",
                "LP_OCR_PATH = 'LP_ocr.pt'\n",
                "\n",
                "# Vehicle Classes (COCO indices or names)\n",
                "VEHICLE_CLASSES = ['car', 'truck', 'bus', 'motorcycle', 'bicycle']\n",
                "\n",
                "# Feature Flags\n",
                "ENABLE_VEHICLE = True\n",
                "ENABLE_TRAFFIC_LIGHT = False\n",
                "ENABLE_LICENSE_PLATE = False\n",
                "\n",
                "# ----------------- GLOBALS -----------------\n",
                "sio = socketio.Client(reconnection=True, ssl_verify=False, logger=False, engineio_logger=False)\n",
                "camera_queues = {}\n",
                "camera_threads = {}\n",
                "running = True\n",
                "connected = False\n",
                "\n",
                "# Models\n",
                "vehicle_model = None\n",
                "traffic_light_model = None\n",
                "lp_detect_model = None\n",
                "lp_ocr_model = None\n",
                "\n",
                "# ----------------- UTILS (LICENSE PLATE) -----------------\n",
                "def changeContrast(img):\n",
                "    lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
                "    l, a, b = cv2.split(lab)\n",
                "    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))\n",
                "    cl = clahe.apply(l)\n",
                "    limg = cv2.merge((cl,a,b))\n",
                "    return cv2.cvtColor(limg, cv2.COLOR_LAB2BGR)\n",
                "\n",
                "def rotate_image(image, angle):\n",
                "    image_center = tuple(np.array(image.shape[1::-1]) / 2)\n",
                "    rot_mat = cv2.getRotationMatrix2D(image_center, angle, 1.0)\n",
                "    return cv2.warpAffine(image, rot_mat, image.shape[1::-1], flags=cv2.INTER_LINEAR)\n",
                "\n",
                "def compute_skew(src_img):\n",
                "    if len(src_img.shape) == 3: h, w, _ = src_img.shape\n",
                "    else: h, w = src_img.shape\n",
                "    img = cv2.medianBlur(src_img, 3)\n",
                "    edges = cv2.Canny(img, 30, 100, apertureSize=3, L2gradient=True)\n",
                "    lines = cv2.HoughLinesP(edges, 1, math.pi/180, 30, minLineLength=w/1.5, maxLineGap=h/3.0)\n",
                "    if lines is None: return 0\n",
                "    \n",
                "    angle = 0.0\n",
                "    cnt = 0\n",
                "    for x1, y1, x2, y2 in lines[:, 0]:\n",
                "        ang = np.arctan2(y2-y1, x2-x1)\n",
                "        if math.fabs(ang) <= 30:\n",
                "            angle += ang\n",
                "            cnt += 1\n",
                "    return (angle / cnt)*180/math.pi if cnt > 0 else 0\n",
                "\n",
                "def deskew(src_img):\n",
                "    return rotate_image(src_img, compute_skew(src_img))\n",
                "\n",
                "def read_plate_yolov5(model, im):\n",
                "    results = model(im)\n",
                "    bb_list = results.pandas().xyxy[0].values.tolist()\n",
                "    if len(bb_list) < 7: return \"unknown\"\n",
                "    \n",
                "    bb_list.sort(key=lambda x: x[0])\n",
                "    ys = [b[1] for b in bb_list]\n",
                "    if max(ys) - min(ys) > im.shape[0] * 0.4:\n",
                "        y_mean = sum(ys) / len(ys)\n",
                "        line1 = sorted([b for b in bb_list if b[1] < y_mean], key=lambda x: x[0])\n",
                "        line2 = sorted([b for b in bb_list if b[1] >= y_mean], key=lambda x: x[0])\n",
                "        text = \"\".join([str(b[-1]) for b in line1]) + \"-\" + \"\".join([str(b[-1]) for b in line2])\n",
                "        return text\n",
                "    else:\n",
                "        return \"\".join([str(b[-1]) for b in bb_list])\n",
                "\n",
                "# ----------------- MODEL LOADING -----------------\n",
                "def load_models():\n",
                "    global vehicle_model, traffic_light_model, lp_detect_model, lp_ocr_model\n",
                "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
                "    print(f\"üöÄ Loading models on {device}...\")\n",
                "\n",
                "    # 1. Vehicle (YOLOv8/11)\n",
                "    if ENABLE_VEHICLE:\n",
                "        try:\n",
                "            print(f\"Loading Vehicle: {VEHICLE_MODEL_PATH}\")\n",
                "            vehicle_model = YOLO(VEHICLE_MODEL_PATH)\n",
                "            vehicle_model.to(device)\n",
                "            print(\"‚úÖ Vehicle Model Loaded (v8/11)\")\n",
                "        except Exception as e: print(f\"‚ùå Vehicle Load Error: {e}\")\n",
                "\n",
                "    # 2. Traffic Light (YOLOv8/11)\n",
                "    if ENABLE_TRAFFIC_LIGHT:\n",
                "        try:\n",
                "            print(f\"Loading Traffic Light: {TRAFFIC_LIGHT_MODEL_PATH}\")\n",
                "            traffic_light_model = YOLO(TRAFFIC_LIGHT_MODEL_PATH)\n",
                "            traffic_light_model.to(device)\n",
                "            print(\"‚úÖ Traffic Light Model Loaded (v8/11)\")\n",
                "        except Exception as e: print(f\"‚ùå TL Load Error: {e}\")\n",
                "\n",
                "    # 3. License Plate (YOLOv5)\n",
                "    if ENABLE_LICENSE_PLATE:\n",
                "        try:\n",
                "            print(f\"Loading LP Detector (v5): {LP_DETECTOR_PATH}\")\n",
                "            sys.path.insert(0, os.getcwd())\n",
                "            lp_detect_model = torch.hub.load('ultralytics/yolov5', 'custom', path=LP_DETECTOR_PATH, force_reload=True)\n",
                "            lp_detect_model.to(device)\n",
                "            lp_detect_model.conf = 0.3\n",
                "            \n",
                "            print(f\"Loading LP OCR (v5): {LP_OCR_PATH}\")\n",
                "            lp_ocr_model = torch.hub.load('ultralytics/yolov5', 'custom', path=LP_OCR_PATH, force_reload=True)\n",
                "            lp_ocr_model.to(device)\n",
                "            lp_ocr_model.conf = 0.5\n",
                "            print(\"‚úÖ License Plate Models Loaded (v5)\")\n",
                "        except Exception as e: print(f\"‚ùå LP Load Error: {e}\")\n",
                "\n",
                "# ----------------- INFERENCE -----------------\n",
                "def run_v8_inference(model, frame, classes=None):\n",
                "    if model is None: return []\n",
                "    results = []\n",
                "    h, w = frame.shape[:2]\n",
                "    try:\n",
                "        res = model(frame, verbose=False, conf=CONFIDENCE_THRESHOLD)\n",
                "        for r in res:\n",
                "            for box in r.boxes:\n",
                "                cls_id = int(box.cls[0])\n",
                "                class_name = model.names[cls_id]\n",
                "                if classes and class_name not in classes: continue\n",
                "                x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
                "                results.append({\n",
                "                    'class': class_name,\n",
                "                    'confidence': float(box.conf[0]),\n",
                "                    'bbox': {'x1': x1/w, 'y1': y1/h, 'x2': x2/w, 'y2': y2/h}\n",
                "                })\n",
                "    except Exception as e: print(f\"Inference v8 error: {e}\")\n",
                "    return results\n",
                "\n",
                "def run_lp_inference(frame):\n",
                "    if lp_detect_model is None or lp_ocr_model is None: return []\n",
                "    results = []\n",
                "    h, w = frame.shape[:2]\n",
                "    try:\n",
                "        preds = lp_detect_model(frame, size=640)\n",
                "        df = preds.pandas().xyxy[0]\n",
                "        for _, row in df.iterrows():\n",
                "            if row['confidence'] < 0.3: continue\n",
                "            x1, y1, x2, y2 = int(row['xmin']), int(row['ymin']), int(row['xmax']), int(row['ymax'])\n",
                "            crop = frame[y1:y2, x1:x2]\n",
                "            if crop.size == 0: continue\n",
                "            \n",
                "            text = \"unknown\"\n",
                "            try:\n",
                "                text = read_plate_yolov5(lp_ocr_model, crop)\n",
                "                if text == \"unknown\":\n",
                "                    text = read_plate_yolov5(lp_ocr_model, deskew(crop))\n",
                "            except: pass\n",
                "            \n",
                "            if text != \"unknown\":\n",
                "                results.append({\n",
                "                    'type': 'license_plate',\n",
                "                    'text': text,\n",
                "                    'bbox': {'x1': x1/w, 'y1': y1/h, 'x2': x2/w, 'y2': y2/h},\n",
                "                    'confidence': row['confidence']\n",
                "                })\n",
                "    except Exception as e: print(f\"LP Inference error: {e}\")\n",
                "    return results\n",
                "\n",
                "# ----------------- MAIN LOOP -----------------\n",
                "def process_camera(camera_id):\n",
                "    global running\n",
                "    print(f\"üìπ Cam {camera_id} loop started\")\n",
                "    while running:\n",
                "        try:\n",
                "            data = camera_queues[camera_id].get(timeout=0.1)\n",
                "            frame, cam_id, img_id, created_at = data\n",
                "            start = time.time()\n",
                "            all_dets = []\n",
                "            \n",
                "            if ENABLE_VEHICLE:\n",
                "                dets = run_v8_inference(vehicle_model, frame, classes=VEHICLE_CLASSES)\n",
                "                for d in dets:\n",
                "                    d['type'] = 'vehicle'\n",
                "                    all_dets.append(d)\n",
                "            \n",
                "            if ENABLE_TRAFFIC_LIGHT:\n",
                "                dets = run_v8_inference(traffic_light_model, frame)\n",
                "                for d in dets: \n",
                "                    d['type'] = 'traffic_light'\n",
                "                    all_dets.append(d)\n",
                "                    \n",
                "            if ENABLE_LICENSE_PLATE:\n",
                "                all_dets.extend(run_lp_inference(frame))\n",
                "            \n",
                "            ms = (time.time() - start) * 1000\n",
                "            if sio.connected and all_dets:\n",
                "                sio.emit('car_detected', {\n",
                "                    'camera_id': cam_id, 'image_id': img_id,\n",
                "                    'detections': all_dets, 'inference_time': ms,\n",
                "                    'created_at': created_at\n",
                "                })\n",
                "                print(f\"  ‚úÖ Cam {cam_id[-4:]}: {len(all_dets)} objs ({ms:.0f}ms)\")\n",
                "        except queue.Empty: continue\n",
                "        except Exception: pass\n",
                "\n",
                "# ----------------- EVENTS -----------------\n",
                "@sio.event\n",
                "def connect():\n",
                "    global connected\n",
                "    connected = True\n",
                "    print(f\"‚úÖ Connected to {SOCKETIO_SERVER_URL}\")\n",
                "    sio.emit(\"join_all_camera\")\n",
                "\n",
                "@sio.event\n",
                "def disconnect():\n",
                "    global connected\n",
                "    connected = False\n",
                "    print(\"‚ö†Ô∏è Disconnected\")\n",
                "\n",
                "@sio.on('image')\n",
                "def on_image(data):\n",
                "    try:\n",
                "        img_data = data.get('image') or data.get('buffer')\n",
                "        if isinstance(img_data, dict): img_data = bytes(img_data.get('data', []))\n",
                "        if isinstance(img_data, str): img_data = base64.b64decode(img_data)\n",
                "        frame = cv2.imdecode(np.frombuffer(img_data, np.uint8), cv2.IMREAD_COLOR)\n",
                "        if frame is None: return\n",
                "        \n",
                "        cid = data['cameraId']\n",
                "        if cid not in camera_queues:\n",
                "            camera_queues[cid] = queue.Queue(maxsize=2)\n",
                "            threading.Thread(target=process_camera, args=(cid,), daemon=True).start()\n",
                "        \n",
                "        q = camera_queues[cid]\n",
                "        if q.full(): \n",
                "            try: q.get_nowait()\n",
                "            except: pass\n",
                "        q.put((frame, cid, data['imageId'], data.get('created_at', 0)))\n",
                "    except: pass\n",
                "\n",
                "def maintain():\n",
                "    while running:\n",
                "        if not sio.connected:\n",
                "            print(f\"üîÑ Connecting to {SOCKETIO_SERVER_URL}...\")\n",
                "            try: \n",
                "                sio.connect(SOCKETIO_SERVER_URL, transports=['websocket'])\n",
                "                print(\"‚úÖ Socket connected!\")\n",
                "            except Exception as e: \n",
                "                print(f\"‚ùå Connection failed: {e}\")\n",
                "                time.sleep(5)\n",
                "        time.sleep(1)\n",
                "\n",
                "if __name__ == \"__main__\":\n",
                "    load_models()\n",
                "    threading.Thread(target=maintain, daemon=True).start()\n",
                "    try:\n",
                "        while running: time.sleep(10)\n",
                "    except: running = False"
            ]
        }
    ],
    "metadata": {
        "kaggle": {
            "accelerator": "gpu",
            "dataSources": [],
            "isGpuEnabled": true,
            "isInternetEnabled": true,
            "language": "python",
            "sourceType": "notebook"
        },
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
