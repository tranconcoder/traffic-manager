{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üö¶ YOLO Detection Server V22 - Fix YOLOv5 Inference\n",
                "### FIX: YOLOv5 torch.hub uses model.conf instead of conf= param\n",
                "### Features:\n",
                "- ‚úÖ Correct YOLOv5 inference call\n",
                "- ‚úÖ Detailed debug logs\n",
                "- ‚úÖ LP_detector.pt + LP_ocr.pt"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 1: CONFIG\n",
                "BACKEND_URL = 'https://candidates-advertising-morning-interaction.trycloudflare.com'\n",
                "NMS_URL = 'https://firewall-video-latinas-yeah.trycloudflare.com'\n",
                "\n",
                "BACKEND_HTTP_URL = BACKEND_URL\n",
                "BACKEND_WS_URL = BACKEND_URL.replace('https://', 'wss://').replace('http://', 'ws://') + '/ws/kaggle'\n",
                "\n",
                "TRACK_LINE_Y = 50\n",
                "CONFIDENCE = 0.5\n",
                "FRAME_QUEUE_SIZE = 3\n",
                "RESULT_QUEUE_SIZE = 10\n",
                "\n",
                "VEHICLE_CLASSES = ['car', 'truck', 'bus', 'motorcycle', 'bicycle']\n",
                "camera_keys = {}\n",
                "\n",
                "BASE_DIR = '/kaggle/input/phat-trien-iot-nang-cao/pytorch/default/2/'\n",
                "LP_DETECTOR_PATH = BASE_DIR + 'LP_detector.pt'\n",
                "LP_OCR_PATH = BASE_DIR + 'LP_ocr.pt'\n",
                "TL_MODEL_PATH = BASE_DIR + 'mhiot-dentinhieu-best-new.pt'\n",
                "\n",
                "print(f\"üì° Backend: {BACKEND_URL}\")\n",
                "print(f\"üìÅ LP Detector: {LP_DETECTOR_PATH}\")\n",
                "print(f\"üìÅ LP OCR: {LP_OCR_PATH}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 2: Install\n",
                "!pip uninstall -y numpy pillow ultralytics > /dev/null 2>&1\n",
                "!pip install \"numpy<2.0.0\" \"pillow>=10.3.0\" scipy ultralytics opencv-python-headless requests websocket-client supervision --upgrade --quiet\n",
                "!wget -nc -q https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11m.pt\n",
                "\n",
                "import numpy, PIL, supervision\n",
                "print(f'‚úÖ Numpy {numpy.__version__}, PIL {PIL.__version__}, Supervision {supervision.__version__}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 3: Load Models\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "import os, torch\n",
                "from ultralytics import YOLO\n",
                "\n",
                "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
                "print(f'üöÄ Device: {device}')\n",
                "\n",
                "vehicle_model = None\n",
                "traffic_light_model = None\n",
                "lp_detector = None       # YOLOv5 model\n",
                "lp_detector_type = None  # 'ultralytics' or 'yolov5'\n",
                "lp_ocr = None\n",
                "lp_ocr_type = None\n",
                "\n",
                "def load_model(path, name):\n",
                "    \"\"\"Load model and return (model, type)\"\"\"\n",
                "    if not os.path.exists(path):\n",
                "        print(f'‚ùå {name}: File not found')\n",
                "        return None, None\n",
                "    \n",
                "    # Try Ultralytics first\n",
                "    try:\n",
                "        model = YOLO(path).to(device)\n",
                "        print(f'‚úÖ {name}: Ultralytics YOLO')\n",
                "        return model, 'ultralytics'\n",
                "    except Exception as e:\n",
                "        print(f'‚ö†Ô∏è {name}: Ultralytics failed, trying YOLOv5... ({str(e)[:50]})')\n",
                "    \n",
                "    # Try YOLOv5\n",
                "    try:\n",
                "        model = torch.hub.load('ultralytics/yolov5', 'custom', path=path, force_reload=False)\n",
                "        model = model.to(device)\n",
                "        model.conf = 0.4  # Set default confidence\n",
                "        model.iou = 0.45  # Set default IOU\n",
                "        print(f'‚úÖ {name}: YOLOv5 (conf={model.conf})')\n",
                "        return model, 'yolov5'\n",
                "    except Exception as e:\n",
                "        print(f'‚ùå {name}: All methods failed: {e}')\n",
                "    \n",
                "    return None, None\n",
                "\n",
                "# Load Vehicle\n",
                "try:\n",
                "    vehicle_model = YOLO('yolo11m.pt').to(device)\n",
                "    print('‚úÖ Vehicle: yolo11m.pt')\n",
                "except Exception as e:\n",
                "    print(f'‚ùå Vehicle: {e}')\n",
                "\n",
                "# Load TL\n",
                "traffic_light_model, _ = load_model(TL_MODEL_PATH, 'Traffic Light')\n",
                "\n",
                "# Load LP Detector (YOLOv5)\n",
                "lp_detector, lp_detector_type = load_model(LP_DETECTOR_PATH, 'LP Detector')\n",
                "\n",
                "# Load LP OCR\n",
                "lp_ocr, lp_ocr_type = load_model(LP_OCR_PATH, 'LP OCR')\n",
                "\n",
                "print('\\n=== MODEL STATUS ===')\n",
                "print(f'vehicle_model: {\"‚úÖ\" if vehicle_model else \"‚ùå\"}')\n",
                "print(f'traffic_light_model: {\"‚úÖ\" if traffic_light_model else \"‚ùå\"}')\n",
                "print(f'lp_detector: {\"‚úÖ\" if lp_detector else \"‚ùå\"} (type: {lp_detector_type})')\n",
                "print(f'lp_ocr: {\"‚úÖ\" if lp_ocr else \"‚ùå\"} (type: {lp_ocr_type})')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 4: Functions with Debug\n",
                "import cv2, numpy as np, time, requests, threading, queue, json\n",
                "from datetime import datetime\n",
                "from collections import deque\n",
                "import supervision as sv\n",
                "\n",
                "camera_trackers = {}\n",
                "camera_positions = {}\n",
                "camera_configs = {}\n",
                "current_traffic_light = {}\n",
                "\n",
                "# Debug counters\n",
                "debug_stats = {'lp_attempts': 0, 'lp_detected': 0, 'ocr_attempts': 0, 'ocr_success': 0}\n",
                "\n",
                "def log(msg):\n",
                "    print(f'[{datetime.now().strftime(\"%H:%M:%S\")}] {msg}')\n",
                "\n",
                "def run_yolov5_inference(model, img, conf_thres=0.4):\n",
                "    \"\"\"Run YOLOv5 inference correctly\"\"\"\n",
                "    model.conf = conf_thres\n",
                "    results = model(img)\n",
                "    return results\n",
                "\n",
                "def run_ultralytics_inference(model, img, conf=0.4, verbose=False):\n",
                "    \"\"\"Run Ultralytics inference\"\"\"\n",
                "    return model(img, conf=conf, verbose=verbose)\n",
                "\n",
                "def read_plate_ocr(plate_crop):\n",
                "    \"\"\"OCR using LP_ocr.pt\"\"\"\n",
                "    global debug_stats\n",
                "    debug_stats['ocr_attempts'] += 1\n",
                "    \n",
                "    if lp_ocr is None:\n",
                "        log('‚ö†Ô∏è OCR: lp_ocr is None')\n",
                "        return 'unknown'\n",
                "    \n",
                "    try:\n",
                "        h, w = plate_crop.shape[:2]\n",
                "        log(f'üìù OCR: Input size {w}x{h}')\n",
                "        \n",
                "        if h < 10 or w < 20:\n",
                "            log('‚ö†Ô∏è OCR: Plate too small')\n",
                "            return 'unknown'\n",
                "        \n",
                "        # Run OCR based on model type\n",
                "        if lp_ocr_type == 'yolov5':\n",
                "            log('üìù OCR: Using YOLOv5 inference')\n",
                "            results = run_yolov5_inference(lp_ocr, plate_crop, conf_thres=0.25)\n",
                "            \n",
                "            # YOLOv5 returns pandas dataframe\n",
                "            if hasattr(results, 'pandas'):\n",
                "                df = results.pandas().xyxy[0]\n",
                "                log(f'üìù OCR: Found {len(df)} chars')\n",
                "                if len(df) >= 4:\n",
                "                    df = df.sort_values('xmin')\n",
                "                    text = ''.join(df['name'].astype(str).tolist()).upper().replace(' ', '').replace('-', '')\n",
                "                    log(f'‚úÖ OCR Result: {text}')\n",
                "                    debug_stats['ocr_success'] += 1\n",
                "                    return text\n",
                "                else:\n",
                "                    log(f'‚ö†Ô∏è OCR: Only {len(df)} chars (need 4+)')\n",
                "        else:\n",
                "            log('üìù OCR: Using Ultralytics inference')\n",
                "            results = run_ultralytics_inference(lp_ocr, plate_crop, conf=0.25)\n",
                "            \n",
                "            if len(results) > 0 and hasattr(results[0], 'boxes'):\n",
                "                chars = []\n",
                "                for b in results[0].boxes:\n",
                "                    x1 = float(b.xyxy[0][0])\n",
                "                    cls_id = int(b.cls[0])\n",
                "                    char = results[0].names[cls_id]\n",
                "                    chars.append((x1, char))\n",
                "                \n",
                "                log(f'üìù OCR: Found {len(chars)} chars')\n",
                "                if len(chars) >= 4:\n",
                "                    chars.sort(key=lambda x: x[0])\n",
                "                    text = ''.join([c[1] for c in chars]).upper().replace(' ', '').replace('-', '')\n",
                "                    log(f'‚úÖ OCR Result: {text}')\n",
                "                    debug_stats['ocr_success'] += 1\n",
                "                    return text\n",
                "                else:\n",
                "                    log(f'‚ö†Ô∏è OCR: Only {len(chars)} chars (need 4+)')\n",
                "        \n",
                "        return 'unknown'\n",
                "    except Exception as e:\n",
                "        log(f'‚ùå OCR Error: {e}')\n",
                "        import traceback; traceback.print_exc()\n",
                "        return 'unknown'\n",
                "\n",
                "def detect_license_plate(frame, x1, y1, x2, y2):\n",
                "    \"\"\"Detect plate and run OCR\"\"\"\n",
                "    global debug_stats\n",
                "    debug_stats['lp_attempts'] += 1\n",
                "    \n",
                "    if lp_detector is None:\n",
                "        if debug_stats['lp_attempts'] <= 3:\n",
                "            log('‚ö†Ô∏è LP: lp_detector is None')\n",
                "        return None\n",
                "    \n",
                "    try:\n",
                "        crop = frame[y1:y2, x1:x2]\n",
                "        crop_h, crop_w = crop.shape[:2]\n",
                "        \n",
                "        if debug_stats['lp_attempts'] % 50 == 1:\n",
                "            log(f'üîç LP: Processing crop {crop_w}x{crop_h}')\n",
                "        \n",
                "        # Run detection based on model type\n",
                "        if lp_detector_type == 'yolov5':\n",
                "            results = run_yolov5_inference(lp_detector, crop, conf_thres=0.4)\n",
                "            \n",
                "            # YOLOv5 pandas result\n",
                "            if hasattr(results, 'pandas'):\n",
                "                df = results.pandas().xyxy[0]\n",
                "                if len(df) == 0:\n",
                "                    return None\n",
                "                \n",
                "                log(f'üîç LP: Found {len(df)} plate boxes')\n",
                "                debug_stats['lp_detected'] += 1\n",
                "                \n",
                "                # Get best detection\n",
                "                best = df.iloc[df['confidence'].idxmax()]\n",
                "                px1, py1, px2, py2 = int(best['xmin']), int(best['ymin']), int(best['xmax']), int(best['ymax'])\n",
                "                plate_crop = crop[py1:py2, px1:px2]\n",
                "                \n",
                "                log(f'üîç LP: Plate box [{px1},{py1},{px2},{py2}]')\n",
                "                \n",
                "                text = read_plate_ocr(plate_crop)\n",
                "                if text != 'unknown':\n",
                "                    return {'text': text, 'confidence': float(best['confidence'])}\n",
                "        else:\n",
                "            results = run_ultralytics_inference(lp_detector, crop, conf=0.4)\n",
                "            \n",
                "            if len(results) > 0 and len(results[0].boxes) > 0:\n",
                "                boxes = results[0].boxes\n",
                "                log(f'üîç LP: Found {len(boxes)} plate boxes')\n",
                "                debug_stats['lp_detected'] += 1\n",
                "                \n",
                "                # Get best\n",
                "                best_conf = 0\n",
                "                best_result = None\n",
                "                for b in boxes:\n",
                "                    conf = float(b.conf[0])\n",
                "                    if conf > best_conf:\n",
                "                        best_conf = conf\n",
                "                        px1, py1, px2, py2 = map(int, b.xyxy[0])\n",
                "                        plate_crop = crop[py1:py2, px1:px2]\n",
                "                        text = read_plate_ocr(plate_crop)\n",
                "                        if text != 'unknown':\n",
                "                            best_result = {'text': text, 'confidence': best_conf}\n",
                "                return best_result\n",
                "        \n",
                "        return None\n",
                "    except Exception as e:\n",
                "        log(f'‚ùå LP Error: {e}')\n",
                "        import traceback; traceback.print_exc()\n",
                "        return None\n",
                "\n",
                "def check_red_light_violation(track_id, prev_y, curr_y, camera_id, img_height):\n",
                "    if current_traffic_light.get(camera_id, 'UNKNOWN') != 'RED':\n",
                "        return False\n",
                "    line_y = (TRACK_LINE_Y / 100) * img_height\n",
                "    if prev_y is not None and prev_y < line_y <= curr_y:\n",
                "        return True\n",
                "    return False\n",
                "\n",
                "def check_lane_violation(vehicle_class, center_x, camera_id, img_width):\n",
                "    config = camera_configs.get(camera_id)\n",
                "    if not config:\n",
                "        return False\n",
                "    lane_points = config.get('camera_lane_track_point', [])\n",
                "    lane_vehicles = config.get('camera_lane_vehicles', [])\n",
                "    if not lane_points or not lane_vehicles:\n",
                "        return False\n",
                "    x_pct = (center_x / img_width) * 100\n",
                "    boundaries = [0] + sorted(lane_points) + [100]\n",
                "    for i in range(len(boundaries) - 1):\n",
                "        if boundaries[i] <= x_pct < boundaries[i + 1]:\n",
                "            if i < len(lane_vehicles):\n",
                "                allowed = lane_vehicles[i]\n",
                "                if isinstance(allowed, list):\n",
                "                    if 'ANY' in [v.upper() for v in allowed]:\n",
                "                        return False\n",
                "                    if vehicle_class.lower() not in [v.lower() for v in allowed]:\n",
                "                        return True\n",
                "            break\n",
                "    return False"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 5: Main Detection V22\n",
                "\n",
                "def detect_frame(frame, camera_id):\n",
                "    global current_traffic_light\n",
                "    \n",
                "    h, w = frame.shape[:2]\n",
                "    result = {\n",
                "        'camera_id': camera_id,\n",
                "        'created_at': int(time.time() * 1000),\n",
                "        'image_dimensions': {'width': w, 'height': h},\n",
                "        'detections': [],\n",
                "        'vehicle_count': 0,\n",
                "        'tracks': [],\n",
                "        'new_crossings': [],\n",
                "        'license_plates': [],\n",
                "        'violations': []\n",
                "    }\n",
                "    \n",
                "    if camera_id not in camera_trackers:\n",
                "        camera_trackers[camera_id] = sv.ByteTrack()\n",
                "        camera_positions[camera_id] = {}\n",
                "        log(f'[{camera_id[-4:]}] ByteTrack created')\n",
                "    \n",
                "    tracker = camera_trackers[camera_id]\n",
                "    positions = camera_positions[camera_id]\n",
                "    \n",
                "    # Traffic Light\n",
                "    if traffic_light_model:\n",
                "        try:\n",
                "            tl_results = run_ultralytics_inference(traffic_light_model, frame, conf=0.4)\n",
                "            status = 'UNKNOWN'\n",
                "            tl_dets = []\n",
                "            for b in tl_results[0].boxes:\n",
                "                cls_name = tl_results[0].names[int(b.cls[0])].lower()\n",
                "                bx1, by1, bx2, by2 = map(float, b.xyxy[0])\n",
                "                tl_dets.append({'class': cls_name, 'confidence': float(b.conf[0]), 'bbox': {'x1': bx1/w, 'y1': by1/h, 'x2': bx2/w, 'y2': by2/h}})\n",
                "                if 'red' in cls_name: status = 'RED'\n",
                "                elif 'green' in cls_name and status != 'RED': status = 'GREEN'\n",
                "            result['traffic_light'] = {'status': status, 'detections': tl_dets}\n",
                "            current_traffic_light[camera_id] = status\n",
                "        except Exception as e:\n",
                "            log(f'TL err: {e}')\n",
                "    \n",
                "    # Vehicle Detection\n",
                "    if vehicle_model:\n",
                "        try:\n",
                "            v_results = vehicle_model(frame, classes=[2,3,5,7], conf=CONFIDENCE, verbose=False)[0]\n",
                "            sv_dets = sv.Detections.from_ultralytics(v_results)\n",
                "            tracked = tracker.update_with_detections(sv_dets)\n",
                "            \n",
                "            detections = []\n",
                "            tracks_dict = {}\n",
                "            detected_plates = []\n",
                "            \n",
                "            for i in range(len(tracked)):\n",
                "                x1, y1, x2, y2 = map(int, tracked.xyxy[i])\n",
                "                cx, cy = (x1+x2)//2, (y1+y2)//2\n",
                "                cls_id = int(tracked.class_id[i]) if tracked.class_id is not None else 0\n",
                "                cls = VEHICLE_CLASSES[min(cls_id, len(VEHICLE_CLASSES)-1)]\n",
                "                conf = float(tracked.confidence[i]) if tracked.confidence is not None else 0.5\n",
                "                track_id = int(tracked.tracker_id[i]) if tracked.tracker_id is not None else -1\n",
                "                \n",
                "                det = {\n",
                "                    'class': cls,\n",
                "                    'confidence': conf,\n",
                "                    'bbox': {'x1': x1/w, 'y1': y1/h, 'x2': x2/w, 'y2': y2/h},\n",
                "                    'center': {'x': cx, 'y': cy},\n",
                "                    'track_id': track_id\n",
                "                }\n",
                "                tracks_dict[track_id] = {'pos': (cx, cy), 'class': cls}\n",
                "                \n",
                "                lp_text = None\n",
                "                lp_conf = 0.0\n",
                "                \n",
                "                # LP Detection\n",
                "                area = (x2-x1)*(y2-y1)\n",
                "                if area > (w*h)*0.005:\n",
                "                    lp_info = detect_license_plate(frame, x1, y1, x2, y2)\n",
                "                    if lp_info and lp_info['text'] != 'unknown':\n",
                "                        lp_text = lp_info['text']\n",
                "                        lp_conf = lp_info['confidence']\n",
                "                        det['license_plate'] = lp_text\n",
                "                        detected_plates.append(lp_text)\n",
                "                        if lp_text not in [p['plate'] for p in result['license_plates']]:\n",
                "                            result['license_plates'].append({'plate': lp_text, 'vehicle_id': track_id, 'confidence': lp_conf})\n",
                "                \n",
                "                # Violations\n",
                "                prev_y = positions.get(track_id)\n",
                "                if check_red_light_violation(track_id, prev_y, cy, camera_id, h):\n",
                "                    if not lp_text:\n",
                "                        lpi = detect_license_plate(frame, x1, y1, x2, y2)\n",
                "                        if lpi: lp_text = lpi['text']; lp_conf = lpi.get('confidence', 0)\n",
                "                    if lp_text and lp_text != 'unknown':\n",
                "                        result['violations'].append({'type': 'RED_LIGHT', 'license_plate': lp_text, 'bbox': det['bbox'], 'detection_id': track_id})\n",
                "                        log(f'üö® RED LIGHT: {lp_text}')\n",
                "                \n",
                "                positions[track_id] = cy\n",
                "                detections.append(det)\n",
                "            \n",
                "            result['detections'] = detections\n",
                "            result['vehicle_count'] = len(detections)\n",
                "            result['tracks'] = [{'id': tid, 'class': info['class'], 'positions': [{'x': info['pos'][0], 'y': info['pos'][1], 'time': result['created_at']}]} for tid, info in tracks_dict.items()]\n",
                "            \n",
                "            if detected_plates:\n",
                "                log(f'üöó LP: {detected_plates}')\n",
                "            \n",
                "        except Exception as e:\n",
                "            log(f'Vehicle err: {e}')\n",
                "            import traceback; traceback.print_exc()\n",
                "    \n",
                "    return result"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 6: WebSocket\n",
                "import websocket, ssl\n",
                "\n",
                "class KaggleWebSocket:\n",
                "    def __init__(self, ws_url, api_key):\n",
                "        self.url = f'{ws_url}?apiKey={api_key}'\n",
                "        self.ws = None\n",
                "        self.connected = False\n",
                "        self.send_queue = queue.Queue(maxsize=RESULT_QUEUE_SIZE)\n",
                "        self._stop = False\n",
                "    \n",
                "    def connect(self):\n",
                "        try:\n",
                "            log(f'üîå Connecting...')\n",
                "            self.ws = websocket.create_connection(self.url, timeout=10, sslopt={'cert_reqs': ssl.CERT_NONE})\n",
                "            self.connected = True\n",
                "            log('‚úÖ WS connected!')\n",
                "            threading.Thread(target=self._sender_loop, daemon=True).start()\n",
                "            return True\n",
                "        except Exception as e:\n",
                "            log(f'‚ùå WS fail: {e}')\n",
                "            return False\n",
                "    \n",
                "    def _sender_loop(self):\n",
                "        while not self._stop:\n",
                "            try:\n",
                "                msg = self.send_queue.get(timeout=1)\n",
                "                if self.ws and self.connected:\n",
                "                    self.ws.send(json.dumps(msg))\n",
                "            except queue.Empty: continue\n",
                "            except Exception as e: log(f'WS err: {e}'); self.connected = False\n",
                "    \n",
                "    def send_async(self, data):\n",
                "        try: self.send_queue.put_nowait(data)\n",
                "        except: pass\n",
                "\n",
                "def fetch_cameras():\n",
                "    global camera_configs, camera_keys\n",
                "    try:\n",
                "        resp = requests.get(f'{BACKEND_HTTP_URL}/api/camera/all', timeout=10)\n",
                "        if resp.status_code == 200:\n",
                "            data = resp.json()\n",
                "            cams = data.get('metadata', data) if isinstance(data, dict) else data\n",
                "            for cam in cams:\n",
                "                if isinstance(cam, dict) and cam.get('_id'):\n",
                "                    cam_id = cam['_id']\n",
                "                    camera_keys[cam_id] = cam.get('camera_api_key', '')\n",
                "                    camera_configs[cam_id] = {\n",
                "                        'camera_lane_track_point': cam.get('camera_lane_track_point', []),\n",
                "                        'camera_lane_vehicles': cam.get('camera_lane_vehicles', [])\n",
                "                    }\n",
                "            return list(camera_keys.keys())\n",
                "    except Exception as e: log(f'Fetch err: {e}')\n",
                "    return []\n",
                "\n",
                "def test_stream(url, timeout=5):\n",
                "    try:\n",
                "        cap = cv2.VideoCapture(url)\n",
                "        cap.set(cv2.CAP_PROP_OPEN_TIMEOUT_MSEC, timeout * 1000)\n",
                "        if cap.isOpened(): ret, _ = cap.read(); cap.release(); return ret\n",
                "        return False\n",
                "    except: return False"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 7: Pipeline V22\n",
                "\n",
                "class CameraPipelineV22:\n",
                "    def __init__(self, camera_id, api_key, kaggle_ws):\n",
                "        self.camera_id = camera_id\n",
                "        self.flv_url = f\"{NMS_URL}/live/{camera_id}.flv\"\n",
                "        self.frame_queue = queue.Queue(maxsize=FRAME_QUEUE_SIZE)\n",
                "        self.kaggle_ws = kaggle_ws\n",
                "        self._stop = False\n",
                "        self.stats = {'frames_read': 0, 'frames_detected': 0, 'violations': 0, 'lp_detected': 0, 'fps': 0}\n",
                "        self.fps_times = deque(maxlen=30)\n",
                "        self.stream_ready = False\n",
                "    \n",
                "    def start(self):\n",
                "        log(f'üé• [{self.camera_id[-4:]}] Testing...')\n",
                "        if not test_stream(self.flv_url, timeout=10): log(f'‚ö†Ô∏è [{self.camera_id[-4:]}] No stream')\n",
                "        threading.Thread(target=self._reader_loop, daemon=True).start()\n",
                "        threading.Thread(target=self._detector_loop, daemon=True).start()\n",
                "        log(f'üöÄ [{self.camera_id[-4:]}] Started')\n",
                "        return True\n",
                "    \n",
                "    def _reader_loop(self):\n",
                "        retry = 2\n",
                "        while not self._stop:\n",
                "            try:\n",
                "                cap = cv2.VideoCapture(self.flv_url)\n",
                "                cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)\n",
                "                if not cap.isOpened(): time.sleep(retry); retry = min(retry*2, 30); continue\n",
                "                self.stream_ready = True; retry = 2\n",
                "                while cap.isOpened() and not self._stop:\n",
                "                    ret, frame = cap.read()\n",
                "                    if not ret: break\n",
                "                    self.stats['frames_read'] += 1\n",
                "                    try: self.frame_queue.put_nowait(frame)\n",
                "                    except: \n",
                "                        try: self.frame_queue.get_nowait(); self.frame_queue.put_nowait(frame)\n",
                "                        except: pass\n",
                "                cap.release(); self.stream_ready = False\n",
                "            except Exception as e: log(f'Reader err: {e}'); time.sleep(retry)\n",
                "    \n",
                "    def _detector_loop(self):\n",
                "        while not self._stop:\n",
                "            try:\n",
                "                frame = self.frame_queue.get(timeout=2)\n",
                "                result = detect_frame(frame, self.camera_id)\n",
                "                self.stats['frames_detected'] += 1\n",
                "                if result.get('violations'): self.stats['violations'] += len(result['violations'])\n",
                "                if result.get('license_plates'): self.stats['lp_detected'] += len(result['license_plates'])\n",
                "                self.kaggle_ws.send_async(result)\n",
                "                \n",
                "                now = time.time()\n",
                "                self.fps_times.append(now)\n",
                "                if len(self.fps_times) > 1: self.stats['fps'] = round(len(self.fps_times) / (self.fps_times[-1] - self.fps_times[0]), 1)\n",
                "                \n",
                "                if self.stats['frames_detected'] % 50 == 0:\n",
                "                    tl = result.get('traffic_light', {}).get('status', '-')\n",
                "                    log(f\"[{self.camera_id[-4:]}] {self.stats['fps']}FPS | Det:{len(result.get('detections',[]))} | TL:{tl} | LP:{self.stats['lp_detected']} | Viol:{self.stats['violations']}\")\n",
                "                    log(f\"üìä Debug: {debug_stats}\")\n",
                "            except queue.Empty: continue\n",
                "            except Exception as e: log(f'Det err: {e}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 8: MAIN\n",
                "log('üîç Fetching cameras...')\n",
                "cameras = fetch_cameras()\n",
                "\n",
                "if not cameras:\n",
                "    log('‚ùå No cameras!')\n",
                "else:\n",
                "    log(f'‚úÖ Found {len(cameras)} cameras')\n",
                "    pipelines = []\n",
                "    for cam_id in cameras:\n",
                "        ws = KaggleWebSocket(BACKEND_WS_URL, camera_keys.get(cam_id, ''))\n",
                "        if not ws.connect(): continue\n",
                "        p = CameraPipelineV22(cam_id, camera_keys.get(cam_id, ''), ws)\n",
                "        if p.start(): pipelines.append(p)\n",
                "        time.sleep(0.5)\n",
                "    \n",
                "    log(f'üöÄ {len(pipelines)} PIPELINES!')\n",
                "    try:\n",
                "        while True:\n",
                "            time.sleep(60)\n",
                "            for p in pipelines:\n",
                "                log(f\"üìä [{p.camera_id[-4:]}] R:{p.stats['frames_read']} D:{p.stats['frames_detected']} FPS:{p.stats['fps']} LP:{p.stats['lp_detected']} V:{p.stats['violations']}\")\n",
                "    except KeyboardInterrupt:\n",
                "        log('Stop')"
            ]
        }
    ],
    "metadata": {
        "kaggle": {
            "accelerator": "gpu",
            "isGpuEnabled": true,
            "isInternetEnabled": true,
            "language": "python",
            "sourceType": "notebook"
        },
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}