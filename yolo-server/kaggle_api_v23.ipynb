{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üö¶ YOLO Detection Server V23\n",
                "### Features:\n",
                "- ‚úÖ LP_detector.pt + LP_ocr.pt (YOLOv5)\n",
                "- ‚úÖ Summary log every 3 seconds\n",
                "- ‚úÖ Supervision ByteTrack"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 1: CONFIG\n",
                "BACKEND_URL = 'https://candidates-advertising-morning-interaction.trycloudflare.com'\n",
                "NMS_URL = 'https://firewall-video-latinas-yeah.trycloudflare.com'\n",
                "\n",
                "BACKEND_HTTP_URL = BACKEND_URL\n",
                "BACKEND_WS_URL = BACKEND_URL.replace('https://', 'wss://').replace('http://', 'ws://') + '/ws/kaggle'\n",
                "\n",
                "TRACK_LINE_Y = 50\n",
                "CONFIDENCE = 0.5\n",
                "FRAME_QUEUE_SIZE = 3\n",
                "RESULT_QUEUE_SIZE = 10\n",
                "LOG_INTERVAL = 3  # seconds\n",
                "\n",
                "VEHICLE_CLASSES = ['car', 'truck', 'bus', 'motorcycle', 'bicycle']\n",
                "camera_keys = {}\n",
                "\n",
                "BASE_DIR = '/kaggle/input/phat-trien-iot-nang-cao/pytorch/default/2/'\n",
                "LP_DETECTOR_PATH = BASE_DIR + 'LP_detector.pt'\n",
                "LP_OCR_PATH = BASE_DIR + 'LP_ocr.pt'\n",
                "TL_MODEL_PATH = BASE_DIR + 'mhiot-dentinhieu-best-new.pt'\n",
                "\n",
                "print(f\"üì° Backend: {BACKEND_URL}\")\n",
                "print(f\"üìÅ LP: {LP_DETECTOR_PATH}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 2: Install\n",
                "!pip uninstall -y numpy pillow ultralytics > /dev/null 2>&1\n",
                "!pip install \"numpy<2.0.0\" \"pillow>=10.3.0\" scipy ultralytics opencv-python-headless requests websocket-client supervision --upgrade --quiet\n",
                "!wget -nc -q https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11m.pt\n",
                "\n",
                "import numpy, PIL, supervision\n",
                "print(f'‚úÖ Numpy {numpy.__version__}, PIL {PIL.__version__}, Supervision {supervision.__version__}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 3: Load Models\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "import os, torch\n",
                "from ultralytics import YOLO\n",
                "\n",
                "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
                "print(f'üöÄ Device: {device}')\n",
                "\n",
                "vehicle_model = None\n",
                "traffic_light_model = None\n",
                "lp_detector = None\n",
                "lp_ocr = None\n",
                "\n",
                "def load_yolov5_model(path, name):\n",
                "    if not os.path.exists(path):\n",
                "        print(f'‚ùå {name}: Not found')\n",
                "        return None\n",
                "    try:\n",
                "        model = torch.hub.load('ultralytics/yolov5', 'custom', path=path, force_reload=False)\n",
                "        model = model.to(device)\n",
                "        model.conf = 0.4\n",
                "        model.iou = 0.45\n",
                "        print(f'‚úÖ {name}: YOLOv5')\n",
                "        return model\n",
                "    except Exception as e:\n",
                "        print(f'‚ùå {name}: {e}')\n",
                "        return None\n",
                "\n",
                "def load_ultralytics_model(path, name):\n",
                "    if not os.path.exists(path):\n",
                "        print(f'‚ùå {name}: Not found')\n",
                "        return None\n",
                "    try:\n",
                "        model = YOLO(path).to(device)\n",
                "        print(f'‚úÖ {name}: Ultralytics')\n",
                "        return model\n",
                "    except Exception as e:\n",
                "        print(f'‚ùå {name}: {e}')\n",
                "        return None\n",
                "\n",
                "vehicle_model = YOLO('yolo11m.pt').to(device)\n",
                "print('‚úÖ Vehicle: yolo11m.pt')\n",
                "\n",
                "traffic_light_model = load_ultralytics_model(TL_MODEL_PATH, 'Traffic Light')\n",
                "lp_detector = load_yolov5_model(LP_DETECTOR_PATH, 'LP Detector')\n",
                "lp_ocr = load_yolov5_model(LP_OCR_PATH, 'LP OCR')\n",
                "\n",
                "print('\\n=== MODELS ===')\n",
                "print(f'Vehicle: {\"‚úÖ\" if vehicle_model else \"‚ùå\"}')\n",
                "print(f'TL: {\"‚úÖ\" if traffic_light_model else \"‚ùå\"}')\n",
                "print(f'LP: {\"‚úÖ\" if lp_detector else \"‚ùå\"}')\n",
                "print(f'OCR: {\"‚úÖ\" if lp_ocr else \"‚ùå\"}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 4: Functions + Stats Tracking\n",
                "import cv2, numpy as np, time, requests, threading, queue, json\n",
                "from datetime import datetime\n",
                "from collections import deque, defaultdict\n",
                "import supervision as sv\n",
                "\n",
                "camera_trackers = {}\n",
                "camera_positions = {}\n",
                "camera_configs = {}\n",
                "current_traffic_light = {}\n",
                "\n",
                "# Per-camera stats for logging\n",
                "camera_stats = defaultdict(lambda: {\n",
                "    'last_log_time': 0,\n",
                "    'vehicle_counts': {'car': 0, 'truck': 0, 'bus': 0, 'motorcycle': 0, 'bicycle': 0},\n",
                "    'plates_detected': set(),\n",
                "    'traffic_light': 'UNKNOWN',\n",
                "    'violations': [],\n",
                "    'fps': 0\n",
                "})\n",
                "\n",
                "def log(msg):\n",
                "    print(f'[{datetime.now().strftime(\"%H:%M:%S\")}] {msg}')\n",
                "\n",
                "def print_summary(camera_id):\n",
                "    \"\"\"Print summary every LOG_INTERVAL seconds\"\"\"\n",
                "    stats = camera_stats[camera_id]\n",
                "    now = time.time()\n",
                "    \n",
                "    if now - stats['last_log_time'] < LOG_INTERVAL:\n",
                "        return\n",
                "    \n",
                "    stats['last_log_time'] = now\n",
                "    \n",
                "    # Build summary\n",
                "    vc = stats['vehicle_counts']\n",
                "    total = sum(vc.values())\n",
                "    vehicles = f\"üöó{vc['car']} üöö{vc['truck']} üöå{vc['bus']} üèçÔ∏è{vc['motorcycle']}\"\n",
                "    \n",
                "    plates = list(stats['plates_detected'])[-5:]  # Last 5 plates\n",
                "    plates_str = ', '.join(plates) if plates else 'none'\n",
                "    \n",
                "    tl = stats['traffic_light']\n",
                "    tl_icon = 'üî¥' if tl == 'RED' else 'üü¢' if tl == 'GREEN' else 'üü°' if tl == 'YELLOW' else '‚ö™'\n",
                "    \n",
                "    viols = stats['violations'][-3:]  # Last 3 violations\n",
                "    viols_str = ', '.join([f\"{v['type']}:{v['plate']}\" for v in viols]) if viols else 'none'\n",
                "    \n",
                "    log(f\"\\n{'='*50}\")\n",
                "    log(f\"üì∑ Camera [{camera_id[-4:]}] | {stats['fps']:.1f} FPS\")\n",
                "    log(f\"üö¶ Traffic Light: {tl_icon} {tl}\")\n",
                "    log(f\"üöó Vehicles ({total}): {vehicles}\")\n",
                "    log(f\"üìã Plates: {plates_str}\")\n",
                "    log(f\"‚ö†Ô∏è Violations: {viols_str}\")\n",
                "    log(f\"{'='*50}\\n\")\n",
                "    \n",
                "    # Reset counts for next interval\n",
                "    stats['vehicle_counts'] = {'car': 0, 'truck': 0, 'bus': 0, 'motorcycle': 0, 'bicycle': 0}\n",
                "    stats['plates_detected'] = set()\n",
                "\n",
                "def read_plate_ocr(plate_crop):\n",
                "    if lp_ocr is None:\n",
                "        return 'unknown'\n",
                "    try:\n",
                "        h, w = plate_crop.shape[:2]\n",
                "        if h < 10 or w < 20:\n",
                "            return 'unknown'\n",
                "        lp_ocr.conf = 0.25\n",
                "        results = lp_ocr(plate_crop)\n",
                "        df = results.pandas().xyxy[0]\n",
                "        if len(df) >= 4:\n",
                "            df = df.sort_values('xmin')\n",
                "            return ''.join(df['name'].astype(str).tolist()).upper().replace(' ', '').replace('-', '')\n",
                "        return 'unknown'\n",
                "    except:\n",
                "        return 'unknown'\n",
                "\n",
                "def detect_license_plate(frame, x1, y1, x2, y2):\n",
                "    if lp_detector is None:\n",
                "        return None\n",
                "    try:\n",
                "        crop = frame[y1:y2, x1:x2]\n",
                "        lp_detector.conf = 0.4\n",
                "        results = lp_detector(crop)\n",
                "        df = results.pandas().xyxy[0]\n",
                "        if len(df) == 0:\n",
                "            return None\n",
                "        best = df.iloc[df['confidence'].idxmax()]\n",
                "        px1, py1, px2, py2 = int(best['xmin']), int(best['ymin']), int(best['xmax']), int(best['ymax'])\n",
                "        plate_crop = crop[py1:py2, px1:px2]\n",
                "        text = read_plate_ocr(plate_crop)\n",
                "        if text != 'unknown':\n",
                "            return {'text': text, 'confidence': float(best['confidence'])}\n",
                "        return None\n",
                "    except:\n",
                "        return None\n",
                "\n",
                "def check_red_light_violation(track_id, prev_y, curr_y, camera_id, img_height):\n",
                "    if current_traffic_light.get(camera_id, 'UNKNOWN') != 'RED':\n",
                "        return False\n",
                "    line_y = (TRACK_LINE_Y / 100) * img_height\n",
                "    if prev_y is not None and prev_y < line_y <= curr_y:\n",
                "        return True\n",
                "    return False\n",
                "\n",
                "def check_lane_violation(vehicle_class, center_x, camera_id, img_width):\n",
                "    config = camera_configs.get(camera_id)\n",
                "    if not config: return False\n",
                "    lane_points = config.get('camera_lane_track_point', [])\n",
                "    lane_vehicles = config.get('camera_lane_vehicles', [])\n",
                "    if not lane_points or not lane_vehicles: return False\n",
                "    x_pct = (center_x / img_width) * 100\n",
                "    boundaries = [0] + sorted(lane_points) + [100]\n",
                "    for i in range(len(boundaries) - 1):\n",
                "        if boundaries[i] <= x_pct < boundaries[i + 1]:\n",
                "            if i < len(lane_vehicles):\n",
                "                allowed = lane_vehicles[i]\n",
                "                if isinstance(allowed, list):\n",
                "                    if 'ANY' in [v.upper() for v in allowed]: return False\n",
                "                    if vehicle_class.lower() not in [v.lower() for v in allowed]: return True\n",
                "            break\n",
                "    return False"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 5: Main Detection\n",
                "\n",
                "def detect_frame(frame, camera_id):\n",
                "    global current_traffic_light\n",
                "    stats = camera_stats[camera_id]\n",
                "    \n",
                "    h, w = frame.shape[:2]\n",
                "    result = {\n",
                "        'camera_id': camera_id,\n",
                "        'created_at': int(time.time() * 1000),\n",
                "        'image_dimensions': {'width': w, 'height': h},\n",
                "        'detections': [],\n",
                "        'vehicle_count': 0,\n",
                "        'tracks': [],\n",
                "        'new_crossings': [],\n",
                "        'license_plates': [],\n",
                "        'violations': []\n",
                "    }\n",
                "    \n",
                "    if camera_id not in camera_trackers:\n",
                "        camera_trackers[camera_id] = sv.ByteTrack()\n",
                "        camera_positions[camera_id] = {}\n",
                "    \n",
                "    tracker = camera_trackers[camera_id]\n",
                "    positions = camera_positions[camera_id]\n",
                "    \n",
                "    # Traffic Light\n",
                "    if traffic_light_model:\n",
                "        try:\n",
                "            tl_results = traffic_light_model(frame, conf=0.4, verbose=False)\n",
                "            status = 'UNKNOWN'\n",
                "            tl_dets = []\n",
                "            for b in tl_results[0].boxes:\n",
                "                cls_name = tl_results[0].names[int(b.cls[0])].lower()\n",
                "                bx1, by1, bx2, by2 = map(float, b.xyxy[0])\n",
                "                tl_dets.append({'class': cls_name, 'confidence': float(b.conf[0]), 'bbox': {'x1': bx1/w, 'y1': by1/h, 'x2': bx2/w, 'y2': by2/h}})\n",
                "                if 'red' in cls_name: status = 'RED'\n",
                "                elif 'green' in cls_name and status != 'RED': status = 'GREEN'\n",
                "                elif 'yellow' in cls_name and status == 'UNKNOWN': status = 'YELLOW'\n",
                "            result['traffic_light'] = {'status': status, 'detections': tl_dets}\n",
                "            current_traffic_light[camera_id] = status\n",
                "            stats['traffic_light'] = status\n",
                "        except: pass\n",
                "    \n",
                "    # Vehicle\n",
                "    if vehicle_model:\n",
                "        try:\n",
                "            v_results = vehicle_model(frame, classes=[2,3,5,7], conf=CONFIDENCE, verbose=False)[0]\n",
                "            sv_dets = sv.Detections.from_ultralytics(v_results)\n",
                "            tracked = tracker.update_with_detections(sv_dets)\n",
                "            \n",
                "            detections = []\n",
                "            tracks_dict = {}\n",
                "            \n",
                "            for i in range(len(tracked)):\n",
                "                x1, y1, x2, y2 = map(int, tracked.xyxy[i])\n",
                "                cx, cy = (x1+x2)//2, (y1+y2)//2\n",
                "                cls_id = int(tracked.class_id[i]) if tracked.class_id is not None else 0\n",
                "                cls = VEHICLE_CLASSES[min(cls_id, len(VEHICLE_CLASSES)-1)]\n",
                "                conf = float(tracked.confidence[i]) if tracked.confidence is not None else 0.5\n",
                "                track_id = int(tracked.tracker_id[i]) if tracked.tracker_id is not None else -1\n",
                "                \n",
                "                # Count vehicles\n",
                "                if cls in stats['vehicle_counts']:\n",
                "                    stats['vehicle_counts'][cls] += 1\n",
                "                \n",
                "                det = {\n",
                "                    'class': cls,\n",
                "                    'confidence': conf,\n",
                "                    'bbox': {'x1': x1/w, 'y1': y1/h, 'x2': x2/w, 'y2': y2/h},\n",
                "                    'center': {'x': cx, 'y': cy},\n",
                "                    'track_id': track_id\n",
                "                }\n",
                "                tracks_dict[track_id] = {'pos': (cx, cy), 'class': cls}\n",
                "                \n",
                "                lp_text = None\n",
                "                lp_conf = 0.0\n",
                "                \n",
                "                # LP\n",
                "                area = (x2-x1)*(y2-y1)\n",
                "                if area > (w*h)*0.005:\n",
                "                    lp_info = detect_license_plate(frame, x1, y1, x2, y2)\n",
                "                    if lp_info:\n",
                "                        lp_text = lp_info['text']\n",
                "                        lp_conf = lp_info['confidence']\n",
                "                        det['license_plate'] = lp_text\n",
                "                        stats['plates_detected'].add(lp_text)\n",
                "                        if lp_text not in [p['plate'] for p in result['license_plates']]:\n",
                "                            result['license_plates'].append({'plate': lp_text, 'vehicle_id': track_id, 'confidence': lp_conf})\n",
                "                \n",
                "                # Violations\n",
                "                prev_y = positions.get(track_id)\n",
                "                if check_red_light_violation(track_id, prev_y, cy, camera_id, h):\n",
                "                    if not lp_text:\n",
                "                        lpi = detect_license_plate(frame, x1, y1, x2, y2)\n",
                "                        if lpi: lp_text = lpi['text']; lp_conf = lpi.get('confidence', 0)\n",
                "                    if lp_text:\n",
                "                        result['violations'].append({'type': 'RED_LIGHT', 'license_plate': lp_text, 'bbox': det['bbox'], 'detection_id': track_id})\n",
                "                        stats['violations'].append({'type': 'RED_LIGHT', 'plate': lp_text})\n",
                "                        log(f'üö® VIOLATION: RED_LIGHT - {lp_text}')\n",
                "                \n",
                "                if check_lane_violation(cls, cx, camera_id, w):\n",
                "                    if not lp_text:\n",
                "                        lpi = detect_license_plate(frame, x1, y1, x2, y2)\n",
                "                        if lpi: lp_text = lpi['text']\n",
                "                    if lp_text:\n",
                "                        result['violations'].append({'type': 'LANE', 'license_plate': lp_text, 'bbox': det['bbox'], 'detection_id': track_id})\n",
                "                        stats['violations'].append({'type': 'LANE', 'plate': lp_text})\n",
                "                        log(f'üö® VIOLATION: LANE - {lp_text}')\n",
                "                \n",
                "                positions[track_id] = cy\n",
                "                detections.append(det)\n",
                "            \n",
                "            result['detections'] = detections\n",
                "            result['vehicle_count'] = len(detections)\n",
                "            result['tracks'] = [{'id': tid, 'class': info['class'], 'positions': [{'x': info['pos'][0], 'y': info['pos'][1], 'time': result['created_at']}]} for tid, info in tracks_dict.items()]\n",
                "        except Exception as e:\n",
                "            log(f'Vehicle err: {e}')\n",
                "    \n",
                "    # Print summary every 3 seconds\n",
                "    print_summary(camera_id)\n",
                "    \n",
                "    return result"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 6: WebSocket\n",
                "import websocket, ssl\n",
                "\n",
                "class KaggleWebSocket:\n",
                "    def __init__(self, ws_url, api_key):\n",
                "        self.url = f'{ws_url}?apiKey={api_key}'\n",
                "        self.ws = None\n",
                "        self.connected = False\n",
                "        self.send_queue = queue.Queue(maxsize=RESULT_QUEUE_SIZE)\n",
                "        self._stop = False\n",
                "    \n",
                "    def connect(self):\n",
                "        try:\n",
                "            log(f'üîå Connecting...')\n",
                "            self.ws = websocket.create_connection(self.url, timeout=10, sslopt={'cert_reqs': ssl.CERT_NONE})\n",
                "            self.connected = True\n",
                "            log('‚úÖ WS connected!')\n",
                "            threading.Thread(target=self._sender_loop, daemon=True).start()\n",
                "            return True\n",
                "        except Exception as e: log(f'‚ùå WS: {e}'); return False\n",
                "    \n",
                "    def _sender_loop(self):\n",
                "        while not self._stop:\n",
                "            try:\n",
                "                msg = self.send_queue.get(timeout=1)\n",
                "                if self.ws and self.connected: self.ws.send(json.dumps(msg))\n",
                "            except queue.Empty: continue\n",
                "            except Exception as e: log(f'WS err: {e}'); self.connected = False\n",
                "    \n",
                "    def send_async(self, data):\n",
                "        try: self.send_queue.put_nowait(data)\n",
                "        except: pass\n",
                "\n",
                "def fetch_cameras():\n",
                "    global camera_configs, camera_keys\n",
                "    try:\n",
                "        resp = requests.get(f'{BACKEND_HTTP_URL}/api/camera/all', timeout=10)\n",
                "        if resp.status_code == 200:\n",
                "            data = resp.json()\n",
                "            cams = data.get('metadata', data) if isinstance(data, dict) else data\n",
                "            for cam in cams:\n",
                "                if isinstance(cam, dict) and cam.get('_id'):\n",
                "                    cam_id = cam['_id']\n",
                "                    camera_keys[cam_id] = cam.get('camera_api_key', '')\n",
                "                    camera_configs[cam_id] = {\n",
                "                        'camera_lane_track_point': cam.get('camera_lane_track_point', []),\n",
                "                        'camera_lane_vehicles': cam.get('camera_lane_vehicles', [])\n",
                "                    }\n",
                "            return list(camera_keys.keys())\n",
                "    except Exception as e: log(f'Fetch err: {e}')\n",
                "    return []\n",
                "\n",
                "def test_stream(url, timeout=5):\n",
                "    try:\n",
                "        cap = cv2.VideoCapture(url)\n",
                "        cap.set(cv2.CAP_PROP_OPEN_TIMEOUT_MSEC, timeout*1000)\n",
                "        if cap.isOpened(): ret, _ = cap.read(); cap.release(); return ret\n",
                "        return False\n",
                "    except: return False"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 7: Pipeline\n",
                "\n",
                "class CameraPipeline:\n",
                "    def __init__(self, camera_id, api_key, kaggle_ws):\n",
                "        self.camera_id = camera_id\n",
                "        self.flv_url = f\"{NMS_URL}/live/{camera_id}.flv\"\n",
                "        self.frame_queue = queue.Queue(maxsize=FRAME_QUEUE_SIZE)\n",
                "        self.kaggle_ws = kaggle_ws\n",
                "        self._stop = False\n",
                "        self.fps_times = deque(maxlen=30)\n",
                "        self.stream_ready = False\n",
                "    \n",
                "    def start(self):\n",
                "        log(f'üé• [{self.camera_id[-4:]}] Testing...')\n",
                "        if not test_stream(self.flv_url, timeout=10): log(f'‚ö†Ô∏è [{self.camera_id[-4:]}] No stream')\n",
                "        threading.Thread(target=self._reader_loop, daemon=True).start()\n",
                "        threading.Thread(target=self._detector_loop, daemon=True).start()\n",
                "        log(f'üöÄ [{self.camera_id[-4:]}] Started')\n",
                "        return True\n",
                "    \n",
                "    def _reader_loop(self):\n",
                "        retry = 2\n",
                "        while not self._stop:\n",
                "            try:\n",
                "                cap = cv2.VideoCapture(self.flv_url)\n",
                "                cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)\n",
                "                if not cap.isOpened(): time.sleep(retry); retry = min(retry*2, 30); continue\n",
                "                self.stream_ready = True; retry = 2\n",
                "                while cap.isOpened() and not self._stop:\n",
                "                    ret, frame = cap.read()\n",
                "                    if not ret: break\n",
                "                    try: self.frame_queue.put_nowait(frame)\n",
                "                    except: \n",
                "                        try: self.frame_queue.get_nowait(); self.frame_queue.put_nowait(frame)\n",
                "                        except: pass\n",
                "                cap.release(); self.stream_ready = False\n",
                "            except Exception as e: log(f'Reader: {e}'); time.sleep(retry)\n",
                "    \n",
                "    def _detector_loop(self):\n",
                "        while not self._stop:\n",
                "            try:\n",
                "                frame = self.frame_queue.get(timeout=2)\n",
                "                result = detect_frame(frame, self.camera_id)\n",
                "                self.kaggle_ws.send_async(result)\n",
                "                \n",
                "                # Update FPS\n",
                "                now = time.time()\n",
                "                self.fps_times.append(now)\n",
                "                if len(self.fps_times) > 1:\n",
                "                    camera_stats[self.camera_id]['fps'] = len(self.fps_times) / (self.fps_times[-1] - self.fps_times[0])\n",
                "            except queue.Empty: continue\n",
                "            except Exception as e: log(f'Det: {e}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 8: MAIN\n",
                "log('üîç Fetching cameras...')\n",
                "cameras = fetch_cameras()\n",
                "\n",
                "if not cameras:\n",
                "    log('‚ùå No cameras!')\n",
                "else:\n",
                "    log(f'‚úÖ Found {len(cameras)} cameras')\n",
                "    pipelines = []\n",
                "    for cam_id in cameras:\n",
                "        ws = KaggleWebSocket(BACKEND_WS_URL, camera_keys.get(cam_id, ''))\n",
                "        if not ws.connect(): continue\n",
                "        p = CameraPipeline(cam_id, camera_keys.get(cam_id, ''), ws)\n",
                "        if p.start(): pipelines.append(p)\n",
                "        time.sleep(0.5)\n",
                "    \n",
                "    log(f'üöÄ {len(pipelines)} PIPELINES RUNNING!')\n",
                "    try:\n",
                "        while True:\n",
                "            time.sleep(60)\n",
                "    except KeyboardInterrupt:\n",
                "        log('Stop')"
            ]
        }
    ],
    "metadata": {
        "kaggle": {
            "accelerator": "gpu",
            "isGpuEnabled": true,
            "isInternetEnabled": true,
            "language": "python",
            "sourceType": "notebook"
        },
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}