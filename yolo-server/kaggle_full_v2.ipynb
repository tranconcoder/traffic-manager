{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ðŸš¦ Traffic Manager AI - Full Version\n",
                "### Vehicle Detection + Traffic Light + License Plate OCR"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 1: Install Dependencies\n",
                "!pip install ultralytics python-socketio[client] websocket-client opencv-python-headless --quiet\n",
                "!wget -nc -q https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11m.pt\n",
                "import os\n",
                "if not os.path.exists('yolov5'):\n",
                "    !git clone --depth 1 https://github.com/ultralytics/yolov5.git 2>/dev/null\n",
                "print(\"âœ… Dependencies ready!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 2: Load All Models\n",
                "import torch, sys\n",
                "from ultralytics import YOLO\n",
                "\n",
                "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
                "print(f\"ðŸš€ Loading models on {device}...\")\n",
                "\n",
                "VEHICLE_MODEL = 'yolo11m.pt'\n",
                "TRAFFIC_LIGHT_MODEL = 'mhiot-dentinhieu-best-new.pt'\n",
                "LP_DETECTOR_MODEL = 'LP_detector.pt'\n",
                "LP_OCR_MODEL = 'LP_ocr.pt'\n",
                "\n",
                "vehicle_model = None\n",
                "try:\n",
                "    vehicle_model = YOLO(VEHICLE_MODEL).to(device)\n",
                "    print(f\"âœ… Vehicle: {VEHICLE_MODEL}\")\n",
                "except: print(f\"âš ï¸ Vehicle model not found\")\n",
                "\n",
                "tl_model = None\n",
                "try:\n",
                "    tl_model = YOLO(TRAFFIC_LIGHT_MODEL).to(device)\n",
                "    print(f\"âœ… Traffic Light: {TRAFFIC_LIGHT_MODEL}\")\n",
                "except: print(f\"âš ï¸ Traffic Light model not found\")\n",
                "\n",
                "lp_detector = lp_ocr = None\n",
                "try:\n",
                "    sys.path.insert(0, 'yolov5')\n",
                "    lp_detector = torch.hub.load('yolov5', 'custom', path=LP_DETECTOR_MODEL, source='local', verbose=False)\n",
                "    lp_ocr = torch.hub.load('yolov5', 'custom', path=LP_OCR_MODEL, source='local', verbose=False)\n",
                "    lp_detector.to(device); lp_ocr.to(device); lp_detector.conf = 0.3; lp_ocr.conf = 0.5\n",
                "    print(f\"âœ… License Plate: {LP_DETECTOR_MODEL}, {LP_OCR_MODEL}\")\n",
                "except: print(f\"âš ï¸ LP models not found\")\n",
                "\n",
                "print(f\"\\nðŸ“Š V:{'âœ…' if vehicle_model else 'âŒ'} TL:{'âœ…' if tl_model else 'âŒ'} LP:{'âœ…' if lp_detector else 'âŒ'}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 3: Main Detection Service\n",
                "import cv2, numpy as np, socketio, base64, time, threading, queue, logging, warnings, math, re, io\n",
                "from datetime import datetime\n",
                "from PIL import Image\n",
                "\n",
                "# ========== CONFIG ==========\n",
                "SERVER_URL = 'https://liberal-surrounding-lease-estimates.trycloudflare.com'\n",
                "LOG_INTERVAL = 3.0\n",
                "VEHICLE_CLASSES = ['car', 'truck', 'bus', 'motorcycle', 'bicycle']\n",
                "CONFIDENCE = 0.5\n",
                "TRAIL_DURATION = 5.0\n",
                "MAX_TRAIL_POINTS = 30\n",
                "COUNTING_LINE_POSITION = 0.5\n",
                "# ============================\n",
                "\n",
                "logging.getLogger('socketio').setLevel(logging.WARNING)\n",
                "logging.getLogger('engineio').setLevel(logging.WARNING)\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "sio = socketio.Client(reconnection=True, reconnection_attempts=0, reconnection_delay=1, \n",
                "                      ssl_verify=False, logger=False, engineio_logger=False)\n",
                "\n",
                "cam_queues = {}\n",
                "lp_queue = queue.Queue(maxsize=5)\n",
                "running = True\n",
                "stats = {'f': 0, 'v': 0, 'tl': 0, 'lp': 0, 'c': 0, 'dc': 0}\n",
                "last_log_time = 0\n",
                "\n",
                "# State variables\n",
                "current_traffic_light = {}\n",
                "\n",
                "def log(msg): print(f\"[{datetime.now().strftime('%H:%M:%S')}] {msg}\")\n",
                "\n",
                "def should_log():\n",
                "    global last_log_time\n",
                "    now = time.time()\n",
                "    if now - last_log_time >= LOG_INTERVAL:\n",
                "        last_log_time = now\n",
                "        return True\n",
                "    return False\n",
                "\n",
                "# Helper: Check line crossing\n",
                "def check_line_crossing(prev_pos, curr_pos, line_y):\n",
                "    prev_y = prev_pos[1]\n",
                "    curr_y = curr_pos[1]\n",
                "    if prev_y <= line_y and curr_y > line_y:\n",
                "        return 1  # Downward\n",
                "    elif prev_y >= line_y and curr_y < line_y:\n",
                "        return -1 # Upward\n",
                "    return 0\n",
                "\n",
                "# License Plate Helpers\n",
                "def read_plate(model, im):\n",
                "    results = model(im)\n",
                "    bb_list = results.pandas().xyxy[0].values.tolist()\n",
                "    if len(bb_list) < 7 or len(bb_list) > 10: return \"unknown\"\n",
                "    bb_list.sort(key=lambda x: x[0])\n",
                "    ys = [b[1] for b in bb_list]\n",
                "    y_mean = sum(ys) / len(ys)\n",
                "    if max(ys) - min(ys) > im.shape[0] * 0.3:\n",
                "        line1 = sorted([b for b in bb_list if b[1] < y_mean], key=lambda x: x[0])\n",
                "        line2 = sorted([b for b in bb_list if b[1] >= y_mean], key=lambda x: x[0])\n",
                "        return ''.join([str(b[-1]) for b in line1]) + '-' + ''.join([str(b[-1]) for b in line2])\n",
                "    return ''.join([str(b[-1]) for b in bb_list])\n",
                "\n",
                "def deskew(img):\n",
                "    try:\n",
                "        h, w = img.shape[:2]\n",
                "        blur = cv2.medianBlur(img, 3)\n",
                "        edges = cv2.Canny(blur, 30, 100)\n",
                "        lines = cv2.HoughLinesP(edges, 1, math.pi/180, 30, minLineLength=w/2, maxLineGap=h/3)\n",
                "        if lines is None: return img\n",
                "        angle = np.mean([np.arctan2(l[0][3]-l[0][1], l[0][2]-l[0][0]) for l in lines[:5]])\n",
                "        M = cv2.getRotationMatrix2D((w/2, h/2), angle*180/math.pi, 1)\n",
                "        return cv2.warpAffine(img, M, (w, h))\n",
                "    except: return img\n",
                "\n",
                "# Processing Threads\n",
                "def process_camera(cid):\n",
                "    log(f\"ðŸ“¹ Cam {cid[-4:]} started\")\n",
                "    \n",
                "    # Camera-specific tracking state\n",
                "    vehicle_tracks = {}\n",
                "    counted_vehicles = {}\n",
                "    vehicle_counts_up = {vt: 0 for vt in VEHICLE_CLASSES}\n",
                "    vehicle_counts_down = {vt: 0 for vt in VEHICLE_CLASSES}\n",
                "    total_counted_up = 0\n",
                "    total_counted_down = 0\n",
                "    \n",
                "    while running:\n",
                "        try:\n",
                "            data = cam_queues[cid].get(timeout=0.5)\n",
                "            if data is None: continue\n",
                "            f, c, i, t, line_y = data\n",
                "            h, w = f.shape[:2]\n",
                "            \n",
                "            # Update counting line Y relative to current frame\n",
                "            counting_line_y = int(h * COUNTING_LINE_POSITION)\n",
                "            \n",
                "            # --- 1. Vehicle Detection & Tracking ---\n",
                "            det_start = time.time()\n",
                "            detected_objects = []\n",
                "            current_tracks = {} # ID -> {position, time, class}\n",
                "            new_crossings = []\n",
                "            \n",
                "            vehicle_counts = {vt: 0 for vt in VEHICLE_CLASSES}\n",
                "            \n",
                "            if vehicle_model:\n",
                "                results = vehicle_model.track(f, persist=True, verbose=False)\n",
                "                inference_time = (time.time() - det_start) * 1000\n",
                "                \n",
                "                for r in results:\n",
                "                    for b in r.boxes:\n",
                "                        cls = vehicle_model.names[int(b.cls[0])]\n",
                "                        if cls not in VEHICLE_CLASSES or float(b.conf[0]) < CONFIDENCE: continue\n",
                "                        \n",
                "                        x1,y1,x2,y2 = map(int, b.xyxy[0])\n",
                "                        center_x, center_y = (x1+x2)//2, (y1+y2)//2\n",
                "                        \n",
                "                        det = {\n",
                "                            'class': cls,\n",
                "                            'type': 'vehicle',\n",
                "                            'confidence': float(b.conf[0]),\n",
                "                            'bbox': {\n",
                "                                'x1': x1/w, 'y1': y1/h, 'x2': x2/w, 'y2': y2/h,\n",
                "                                'width': (x2-x1)/w, 'height': (y2-y1)/h\n",
                "                            }\n",
                "                        }\n",
                "                        \n",
                "                        track_id = None\n",
                "                        if hasattr(b,'id') and b.id is not None:\n",
                "                            track_id = int(b.id[0])\n",
                "                            det['id'] = track_id\n",
                "                            current_tracks[track_id] = {'position': (center_x, center_y), 'time': t, 'class': cls}\n",
                "                        \n",
                "                        detected_objects.append(det)\n",
                "                        vehicle_counts[cls] += 1\n",
                "                        stats['v'] += 1\n",
                "                \n",
                "                # Update tracks and check crossings\n",
                "                current_time = time.time()\n",
                "                \n",
                "                # Update positions and check crossings\n",
                "                for tid, info in current_tracks.items():\n",
                "                    pos = info['position']\n",
                "                    cls = info['class']\n",
                "                    \n",
                "                    if tid not in vehicle_tracks: vehicle_tracks[tid] = []\n",
                "                    \n",
                "                    if vehicle_tracks[tid]:\n",
                "                        prev_pos = vehicle_tracks[tid][-1]['position']\n",
                "                        c_dir = check_line_crossing(prev_pos, pos, counting_line_y)\n",
                "                        \n",
                "                        if c_dir != 0:\n",
                "                            c_key = f\"{tid}_{c_dir}\"\n",
                "                            if c_key not in counted_vehicles:\n",
                "                                counted_vehicles[c_key] = True\n",
                "                                if c_dir == 1:\n",
                "                                    vehicle_counts_down[cls] += 1\n",
                "                                    total_counted_down += 1\n",
                "                                else:\n",
                "                                    vehicle_counts_up[cls] += 1\n",
                "                                    total_counted_up += 1\n",
                "                                new_crossings.append((tid, c_dir))\n",
                "                    \n",
                "                    vehicle_tracks[tid].append({'position': pos, 'time': info['time'], 'class': cls})\n",
                "                    # Trails cleanup\n",
                "                    vehicle_tracks[tid] = [p for p in vehicle_tracks[tid] if current_time - p.get('real_time', current_time) <= TRAIL_DURATION][-MAX_TRAIL_POINTS:]\n",
                "                \n",
                "                # Cleanup old tracks\n",
                "                # (Simplified cleanup to avoid memory leak in long run)\n",
                "                if len(vehicle_tracks) > 50:\n",
                "                     # Keep only recent\n",
                "                     vehicle_tracks = {k:v for k,v in list(vehicle_tracks.items())[-50:]}\n",
                "\n",
                "                if detected_objects and sio.connected:\n",
                "                    response = {\n",
                "                        'camera_id': c,\n",
                "                        'image_id': i,\n",
                "                        'track_line_y': line_y,\n",
                "                        'detections': detected_objects,\n",
                "                        'inference_time': inference_time,\n",
                "                        'image_dimensions': {'width': w, 'height': h},\n",
                "                        'created_at': t,\n",
                "                        'vehicle_count': {\n",
                "                            'total_up': total_counted_up,\n",
                "                            'total_down': total_counted_down,\n",
                "                            'by_type_up': vehicle_counts_up,\n",
                "                            'by_type_down': vehicle_counts_down,\n",
                "                            'current': vehicle_counts\n",
                "                        },\n",
                "                        'tracks': [\n",
                "                            {\n",
                "                                'id': tid,\n",
                "                                'positions': [{'x': p['position'][0], 'y': p['position'][1], 'time': p['time']} for p in tdata],\n",
                "                                'class': tdata[-1]['class']\n",
                "                            }\n",
                "                            for tid, tdata in vehicle_tracks.items() if tdata and tid in current_tracks\n",
                "                        ],\n",
                "                        'new_crossings': [\n",
                "                            {'id': cr[0], 'direction': cr[1]} for cr in new_crossings\n",
                "                        ]\n",
                "                    }\n",
                "                    sio.emit('car_detected', response)\n",
                "            \n",
                "            # --- 2. Traffic Light Detection ---\n",
                "            if tl_model:\n",
                "                tl_start = time.time()\n",
                "                tl_dets = []\n",
                "                for r in tl_model(f, verbose=False):\n",
                "                    for b in r.boxes:\n",
                "                        if float(b.conf[0]) < 0.4: continue\n",
                "                        x1,y1,x2,y2 = map(int, b.xyxy[0])\n",
                "                        tl_dets.append({'class':tl_model.names[int(b.cls[0])],'confidence':float(b.conf[0]),\n",
                "                                       'bbox':{'x1':x1/w,'y1':y1/h,'x2':x2/w,'y2':y2/h,'width':(x2-x1)/w,'height':(y2-y1)/h}})\n",
                "                        stats['tl'] += 1\n",
                "                \n",
                "                tl_inference = (time.time() - tl_start) * 1000\n",
                "                \n",
                "                if tl_dets and sio.connected:\n",
                "                    max_conf = max(tl_dets, key=lambda x: x['confidence'])\n",
                "                    new_status = max_conf['class']\n",
                "                    old_status = current_traffic_light.get(c, {}).get('status', None)\n",
                "                    if new_status != old_status:\n",
                "                        current_traffic_light[c] = {'status': new_status, 'time': time.time()}\n",
                "                        log(f\"ðŸš¦ {c[-4:]}: {old_status or '?'} â†’ {new_status}\")\n",
                "                    \n",
                "                    sio.emit('traffic_light', {\n",
                "                        'cameraId':c,\n",
                "                        'imageId':i,\n",
                "                        'traffic_status':new_status,\n",
                "                        'detections':tl_dets,\n",
                "                        'created_at':t,\n",
                "                        'inference_time': tl_inference,\n",
                "                        'image_dimensions': {'width': w, 'height': h}\n",
                "                    })\n",
                "            \n",
                "            stats['f'] += 1\n",
                "            if should_log():\n",
                "                tl_status = ' | '.join([f\"{k[-4:]}:{v['status']}\" for k,v in current_traffic_light.items()]) or 'N/A'\n",
                "                log(f\"ðŸ“Š F:{stats['f']} V:{stats['v']} TL:{stats['tl']} LP:{stats['lp']} | ÄÃ¨n: {tl_status}\")\n",
                "            \n",
                "            time.sleep(0.01)\n",
                "        except queue.Empty: pass\n",
                "        except Exception as e: log(f\"âŒ {e}\")\n",
                "\n",
                "def process_license_plate():\n",
                "    log(\"ðŸ”§ LP OCR started\")\n",
                "    while running:\n",
                "        try:\n",
                "            data = lp_queue.get(timeout=0.5)\n",
                "            if data is None: continue\n",
                "            cam_id, img_id, violations, buffer, detections = data\n",
                "            \n",
                "            start_time = time.time()\n",
                "            img = cv2.imdecode(np.frombuffer(buffer, np.uint8), cv2.IMREAD_COLOR)\n",
                "            if img is None: continue\n",
                "            h, w = img.shape[:2]\n",
                "            \n",
                "            plates = lp_detector(img, size=1920)\n",
                "            results = {}\n",
                "            for p in plates.pandas().xyxy[0].values.tolist():\n",
                "                if p[4] < 0.3: continue\n",
                "                x1,y1,x2,y2 = map(int, p[:4])\n",
                "                crop = img[max(0,y1):min(h,y2), max(0,x1):min(w,x2)]\n",
                "                if crop.size == 0: continue\n",
                "                vid = None\n",
                "                for det in detections:\n",
                "                    bx1,by1,bx2,by2 = det['bbox']['x1']*w, det['bbox']['y1']*h, det['bbox']['x2']*w, det['bbox']['y2']*h\n",
                "                    if x1 >= bx1 and x2 <= bx2 and y1 >= by1 and y2 <= by2:\n",
                "                        vid = det.get('id'); break\n",
                "                if vid is None: continue\n",
                "                text = read_plate(lp_ocr, crop)\n",
                "                if text == 'unknown': text = read_plate(lp_ocr, deskew(crop))\n",
                "                if text != 'unknown' and re.match(r'^[0-9]{2}[A-Z]{1,2}[0-9]{1,5}$', text):\n",
                "                    results[vid] = text; stats['lp'] += 1\n",
                "            \n",
                "            inference_time = (time.time() - start_time) * 1000\n",
                "            \n",
                "            if results and sio.connected:\n",
                "                sio.emit('violation_license_plate', {\n",
                "                    'camera_id':cam_id,\n",
                "                    'image_id':img_id,\n",
                "                    'license_plates':results,\n",
                "                    'violations':violations,\n",
                "                    'inference_time': inference_time\n",
                "                })\n",
                "                log(f\"ðŸš— LP: {results}\")\n",
                "        except queue.Empty: pass\n",
                "        except Exception as e: log(f\"âŒ LP: {e}\")\n",
                "\n",
                "# Socket Events\n",
                "@sio.event\n",
                "def connect():\n",
                "    stats['c'] += 1; log(f\"âœ… CONNECTED #{stats['c']}\")\n",
                "    sio.emit('join_all_camera')\n",
                "\n",
                "@sio.event\n",
                "def disconnect():\n",
                "    stats['dc'] += 1; log(f\"âš ï¸ DISCONNECTED #{stats['dc']}\")\n",
                "\n",
                "@sio.on('image')\n",
                "def on_image(d):\n",
                "    try:\n",
                "        buf = d.get('buffer') or d.get('image')\n",
                "        if isinstance(buf, dict): buf = bytes(buf.get('data', []))\n",
                "        if isinstance(buf, str): buf = base64.b64decode(buf)\n",
                "        img = Image.open(io.BytesIO(buf))\n",
                "        f = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)\n",
                "        c = d['cameraId']\n",
                "        if c not in cam_queues:\n",
                "            cam_queues[c] = queue.Queue(maxsize=3)\n",
                "            threading.Thread(target=process_camera, args=(c,), daemon=True).start()\n",
                "        q = cam_queues[c]\n",
                "        while not q.empty():\n",
                "            try: q.get_nowait()\n",
                "            except: break\n",
                "        q.put((f, c, d['imageId'], d.get('created_at',0), d.get('track_line_y',50)))\n",
                "    except: pass\n",
                "\n",
                "@sio.on('violation_detect')\n",
                "def on_violation(d):\n",
                "    try:\n",
                "        if not lp_detector: return\n",
                "        buf = d.get('buffer')\n",
                "        if isinstance(buf, dict): buf = bytes(buf.get('data', []))\n",
                "        lp_queue.put((d.get('camera_id'), d.get('image_id'), d.get('violations'), buf, d.get('detections', [])))\n",
                "    except: pass\n",
                "\n",
                "def initial_connect():\n",
                "    while running and not sio.connected:\n",
                "        log(f\"ðŸ”„ Connecting...\")\n",
                "        try: sio.connect(SERVER_URL, transports=['websocket']); break\n",
                "        except: time.sleep(2)\n",
                "\n",
                "# Start\n",
                "log(f\"ðŸŽ¯ {SERVER_URL}\")\n",
                "if lp_detector: threading.Thread(target=process_license_plate, daemon=True).start()\n",
                "threading.Thread(target=initial_connect, daemon=True).start()\n",
                "\n",
                "try:\n",
                "    while running: time.sleep(60)\n",
                "except: running = False"
            ]
        }
    ],
    "metadata": {
        "kaggle": {
            "accelerator": "gpu",
            "isGpuEnabled": true,
            "isInternetEnabled": true,
            "language": "python",
            "sourceType": "notebook"
        },
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}